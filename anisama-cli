#!/usr/bin/env python3

import requests
import subprocess
import re
import sys
import json
import sqlite3
from bs4 import BeautifulSoup
import os
import time
from datetime import datetime
import locale
import pathlib
import argparse
import asyncio

# ===== COULEURS ANSI =====
RED = R = '\033[91m'
GREEN = G = '\033[92m'
YELLOW = Y = '\033[93m' 
BLUE = B = '\033[94m'
MAGENTA = M = '\033[95m'
CYAN = C = '\033[96m'
WHITE = W = '\033[97m'
RESET = X = '\033[0m'
BOLD = '\033[1m'

def show_banner():
    # Clear terminal for clean interface
    os.system('clear')
    print()
    print(CYAN + "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó" + RESET)
    print(CYAN + "‚ïë  " + YELLOW + "‚ö° Powered by karbonedev + ani-cli UI" + CYAN + "                ‚ïë" + RESET)
    print(CYAN + "‚ïë  " + BLUE + "üá´üá∑ Tip: Use --vf for French !" + CYAN + "       ‚ïë" + RESET)
    print(CYAN + "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù" + RESET)
    print()

def check_deps():
    print(BLUE + "üîç Checking dependencies..." + RESET)
    missing = []
    warnings = []
    
    def check_command(cmd, name):
        try:
            result = subprocess.run([cmd, "--version"], capture_output=True, timeout=3, text=True)
            if result.returncode == 0:
                version = result.stdout.split('\n')[0] if result.stdout else "unknown version"
                print(GREEN + f"  ‚úì {name}: {version[:50]}..." + RESET)
                return True
        except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.CalledProcessError):
            pass
        missing.append(name)
        print(RED + f"  ‚úó {name}: not found" + RESET)
        return False
    
    # Check essential tools
    fzf_ok = check_command("fzf", "fzf")
    mpv_ok = check_command("mpv", "mpv")
    
    # yt-dlp is optional, just warn if missing
    if not check_command("yt-dlp", "yt-dlp"):
        warnings.append("yt-dlp (optional, for some advanced features)")
        missing.pop()  # Remove from missing since it's optional
    
    # Check python deps
    try:
        import requests
        print(GREEN + f"  ‚úì requests: {requests.__version__}" + RESET)
    except ImportError:
        missing.append("python-requests")
        print(RED + "  ‚úó requests: not found" + RESET)
    
    try:
        import bs4
        print(GREEN + f"  ‚úì beautifulsoup4: {bs4.__version__}" + RESET)
    except ImportError:
        missing.append("python-beautifulsoup4")
        print(RED + "  ‚úó beautifulsoup4: not found" + RESET)
    
    if missing:
        show_error_with_solutions('deps', f"Missing: {', '.join(missing)}")
        if not fzf_ok or not mpv_ok:
            die("Critical dependencies missing")
    elif warnings:
        print(YELLOW + f"‚ö†  Optional: {', '.join(warnings)}" + RESET)
    
    if not missing:
        print(GREEN + "‚úì All dependencies found! üöÄ" + RESET)
    print()

def check_connectivity():
    """Check connectivity to streaming services with retry logic"""
    print(BLUE + "üåê Checking streaming services..." + RESET)
    
    def test_service(url, name, retries=2):
        for attempt in range(retries + 1):
            try:
                response = requests.get(url, timeout=8, headers=HEADERS_BASE)
                if response.status_code == 200:
                    print(GREEN + f"‚úì {name} accessible" + RESET)
                    return True
                else:
                    print(YELLOW + f"‚ö† {name} responds with status {response.status_code}" + RESET)
                    return False
            except requests.exceptions.Timeout:
                if attempt < retries:
                    print(YELLOW + f"‚è≥ {name} timeout, retrying..." + RESET)
                    time.sleep(1)
                    continue
                print(YELLOW + f"‚ö† {name} timeout after {retries + 1} attempts" + RESET)
                return False
            except requests.exceptions.ConnectionError:
                print(RED + f"‚úó {name} connection failed" + RESET)
                return False
            except Exception as e:
                print(RED + f"‚úó {name} error: {str(e)[:50]}..." + RESET)
                return False
        return False
    
    # Test both services
    sibnet_ok = test_service("https://video.sibnet.ru/", "Sibnet")
    vidmoly_ok = test_service("https://vidmoly.net/", "Vidmoly") or test_service("https://vidmoly.to/", "Vidmoly (fallback)")
    
    if not sibnet_ok and not vidmoly_ok:
        print(YELLOW + "  üí° Network issues detected. Some animes may not work." + RESET)
    elif not vidmoly_ok:
        print(YELLOW + "  üí° Vidmoly issues detected. Try VPN for Naruto-type animes." + RESET)

# Utility functions for ani-cli style interface
def fzf_select(items, prompt="Select: ", multi=False):
    """Use fzf for selection like ani-cli"""
    if not items:
        return None
    
    if len(items) == 1:
        return items[0]
    
    # Prepare input for fzf
    fzf_input = "\n".join(items)
    
    cmd = ["fzf", "--reverse", "--cycle", f"--prompt={prompt}"]
    if multi:
        cmd.append("-m")
    
    try:
        result = subprocess.run(
            cmd,
            input=fzf_input,
            text=True,
            capture_output=True
        )
        
        if result.returncode == 0:
            selected = result.stdout.strip()
            if multi:
                return selected.split('\n') if selected else []
            return selected
        return None
    except FileNotFoundError:
        print(RED + "‚úó fzf not found! Please install fzf." + RESET)
        return None
    except Exception as e:
        print(RED + f"‚úó Selection error: {e}" + RESET)
        return None

def die(message, suggestion=None):
    """Print error and exit like ani-cli with helpful suggestions"""
    print(f"\r{RED}‚úó {message}{RESET}", file=sys.stderr)
    if suggestion:
        print(f"{YELLOW}üí° Suggestion: {suggestion}{RESET}", file=sys.stderr)
    sys.exit(1)

def show_error_with_solutions(error_type, details=None):
    """Show error with multiple solutions"""
    error_solutions = {
        'network': [
            "Check your internet connection",
            "Try using a VPN if content is geo-blocked",
            "Wait a moment and try again"
        ],
        'no_results': [
            "Try a different search term",
            "Check spelling of anime name", 
            "Use --vf flag for French dub versions",
            "Try searching in English or Japanese romanization"
        ],
        'playback': [
            "Ensure mpv is properly installed",
            "Try a different episode or anime",
            "Check if the streaming service is accessible",
            "Use VPN if you see Vidmoly errors"
        ],
        'deps': [
            "Install missing dependencies: sudo apt install fzf mpv yt-dlp",
            "Install Python packages: pip install requests beautifulsoup4",
            "Check if all commands are in your PATH"
        ]
    }
    
    if error_type in error_solutions:
        print(f"{YELLOW}üí° Try these solutions:{RESET}")
        for i, solution in enumerate(error_solutions[error_type], 1):
            print(f"   {i}. {solution}")
        if details:
            print(f"{BLUE}Details: {details}{RESET}")
    print()

def search_prompt():
    """Interactive search prompt like ani-cli"""
    while True:
        try:
            query = input(f"\033[1;36mSearch anime: \033[0m").strip()
            if query:
                return query
        except (EOFError, KeyboardInterrupt):
            print()
            sys.exit(0)

HEADERS_BASE = {
    "user-agent": "Mozilla/5.0 (X11; Linux x86_64; rv:134.0) Gecko/20100101 Firefox/134.0",
    "accept-language": "en-US,en;q=0.5",
    "connection": "keep-alive"
}

def get_db_path():
    db_dir = os.path.expanduser("~/.local/share/animesama-cli")
    os.makedirs(db_dir, exist_ok=True)
    return os.path.join(db_dir, "history.db")

def init_db():
    conn = sqlite3.connect(get_db_path())
    cursor = conn.cursor()
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS history (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        anime_name TEXT NOT NULL,
        episode TEXT NOT NULL,
        saison TEXT NOT NULL,
        url TEXT NOT NULL,
        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
    )
    ''')
    conn.commit()
    conn.close()

def add_to_history(anime_name, episode, saison, url):
    try:
        init_db()
        conn = sqlite3.connect(get_db_path())
        cursor = conn.cursor()
        cursor.execute(
            "SELECT id FROM history WHERE anime_name = ? AND saison = ?", 
            (anime_name, saison)
        )
        existing_entry = cursor.fetchone()
        if existing_entry:
            cursor.execute(
                "UPDATE history SET episode = ?, timestamp = CURRENT_TIMESTAMP WHERE id = ?",
                (episode, existing_entry[0])
            )
            print(GREEN + "‚úì History updated" + RESET)
        else:
            cursor.execute(
                "INSERT INTO history (anime_name, episode, saison, url) VALUES (?, ?, ?, ?)",
                (anime_name, episode, saison, url)
            )
            print(GREEN + "‚úì Added to history" + RESET)
        conn.commit()
        conn.close()
    except Exception as e:
        print(YELLOW + f"‚ö† History error: {e}" + RESET)

def get_history_entries():
    db_path = get_db_path()
    if not os.path.exists(db_path):
        return []
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("SELECT id, anime_name, episode, saison, url FROM history ORDER BY timestamp DESC")
    entries = cursor.fetchall()
    conn.close()
    return entries

def get_seasons(html_content):
    seasons = []
    pattern = r'panneauAnime\("([^"]+)",\s*"([^"]+)"\)'
    soup = BeautifulSoup(html_content, 'html.parser')
    matches = re.findall(pattern, html_content)
    if not matches:
        return []
    for name, path in matches:
        if "film" not in name.lower() and name.lower() != "nom":
            seasons.append({
                'name': name,
                'url': path
            })
    return seasons

def get_episode_list(url):
    url = url.replace('https://', '')
    headers = {
        "host": "anime-sama.fr",
        "user-agent": "Mozilla/5.0 (X11; Linux x86_64; rv:134.0) Gecko/20100101 Firefox/134.0",
        "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "accept-language": "en-US,en;q=0.5",
        "connection": "keep-alive",
        "upgrade-insecure-requests": "1",
        "sec-fetch-dest": "document",
        "sec-fetch-mode": "navigate",
        "sec-fetch-site": "same-origin",
        "sec-fetch-user": "?1"
    }
    try:
        response = requests.get(f"https://{url}", headers=headers)
        content = response.text
        pattern = r'episodes\.js\?filever=(\d+)'
        match = re.search(pattern, content)
        if match:
            filever = match.group(1)
            return filever
        return None
    except Exception as e:
        print(f"Error: {str(e)}")
        return None

class AnimeDownloader:
    def __init__(self, debug=False):
        self.session = requests.Session()
        self.session.headers.update(HEADERS_BASE)
        self.debug = debug
        self._cache = {}  # Simple in-memory cache
        self._cache_ttl = 300  # 5 minutes cache TTL
        
    def debug_print(self, *args, **kwargs):
        if self.debug:
            print("[DEBUG]", *args, **kwargs)
    
    def _get_cache_key(self, url, params=None):
        """Generate cache key for requests"""
        key = url
        if params:
            sorted_params = sorted(params.items()) if isinstance(params, dict) else params
            key += str(sorted_params)
        return key
    
    def _is_cache_valid(self, timestamp):
        """Check if cache entry is still valid"""
        return time.time() - timestamp < self._cache_ttl
    
    def _cached_request(self, method, url, **kwargs):
        """Make cached HTTP request"""
        cache_key = self._get_cache_key(url, kwargs.get('params'))
        
        # Check cache
        if cache_key in self._cache:
            cached_data, timestamp = self._cache[cache_key]
            if self._is_cache_valid(timestamp):
                self.debug_print(f"Cache hit for {url[:50]}...")
                return cached_data
        
        # Make request with retry logic
        for attempt in range(3):
            try:
                response = getattr(self.session, method.lower())(url, timeout=10, **kwargs)
                response.raise_for_status()
                
                # Cache successful response
                self._cache[cache_key] = (response, time.time())
                if len(self._cache) > 50:  # Limit cache size
                    oldest_key = min(self._cache.keys(), key=lambda k: self._cache[k][1])
                    del self._cache[oldest_key]
                
                return response
                
            except requests.exceptions.Timeout:
                if attempt < 2:
                    self.debug_print(f"Timeout attempt {attempt + 1}, retrying...")
                    time.sleep(1)
                    continue
                raise
            except requests.exceptions.RequestException as e:
                if attempt < 2 and "Connection" in str(e):
                    self.debug_print(f"Connection error attempt {attempt + 1}, retrying...")
                    time.sleep(2)
                    continue
                raise

    def _generate_episode_name(self, episode_number, anime_name=""):
        """Generate simple episode names"""
        return f"Episode {episode_number}"

    def get_anime_episode(self, complete_url, filever):
        complete_url = complete_url.replace('https://', '')
        url = f"https://{complete_url}/episodes.js"
        try:
            response = self._cached_request('get', url, params={"filever": filever})
            content = response.text
            
            # Parse episode arrays (eps1, eps2, eps3, etc.)
            all_links = {}
            
            # Find all episode arrays in the JavaScript
            array_pattern = r'var eps(\d+) = \[(.*?)\];'
            arrays = re.findall(array_pattern, content, re.DOTALL)
            
            if arrays:
                # Determine which server to use (prefer Sibnet, then Vidmoly)
                best_server = None
                best_episodes = []
                
                for array_num, array_content in arrays:
                    self.debug_print(f"Analyzing eps{array_num} array...")
                    
                    # Check for Sibnet links in this array
                    sibnet_matches = list(re.finditer(r'https://video\.sibnet\.ru/shell\.php\?videoid=(\d+)', array_content))
                    if sibnet_matches:
                        best_server = 'sibnet'
                        best_episodes = [(match.group(1), 'sibnet') for match in sibnet_matches]
                        self.debug_print(f"Found {len(sibnet_matches)} Sibnet episodes in eps{array_num}")
                        break  # Prefer Sibnet, stop looking
                    
                    # Check for Vidmoly links in this array
                    vidmoly_matches = list(re.finditer(r'https://vidmoly\.to/embed-([^.]+)\.html', array_content))
                    if vidmoly_matches and not best_server:
                        best_server = 'vidmoly'
                        best_episodes = [(match.group(1), 'vidmoly') for match in vidmoly_matches]
                        self.debug_print(f"Found {len(vidmoly_matches)} Vidmoly episodes in eps{array_num}")
                
                # Now build the episodes dict with simple numbering
                if best_episodes:
                    for i, (video_id, server_type) in enumerate(best_episodes):
                        episode_number = i + 1  # Simple 1-based numbering
                        episode_name = self._generate_episode_name(episode_number, complete_url)
                        # Store both the video data and the episode name
                        all_links[str(episode_number)] = (server_type, video_id, episode_name)
                    
                    self.debug_print(f"Using {best_server} server with {len(best_episodes)} episodes")
            else:
                # Fallback to old method if no arrays found
                self.debug_print("No episode arrays found, using fallback method...")
                
                # Check for Sibnet links first
                sibnet_matches = re.finditer(r'https://video\.sibnet\.ru/shell\.php\?videoid=(\d+)', content)
                sibnet_links = {str(i): ('sibnet', match.group(1)) for i, match in enumerate(sibnet_matches, 1)}
                
                # Check for Vidmoly links
                vidmoly_matches = re.finditer(r'https://vidmoly\.to/embed-([^.]+)\.html', content)
                vidmoly_links = {str(i): ('vidmoly', match.group(1)) for i, match in enumerate(vidmoly_matches, 1)}
                
                # Use the service with the most links available (fallback method)
                sibnet_count = len(sibnet_links)
                vidmoly_count = len(vidmoly_links)
                
                if sibnet_count >= vidmoly_count and sibnet_count > 0:
                    # Convert to new format with simple episode names
                    for ep_num, (service, video_id) in sibnet_links.items():
                        episode_name = self._generate_episode_name(int(ep_num), complete_url)
                        all_links[ep_num] = (service, video_id, episode_name)
                elif vidmoly_count > 0:
                    # Convert to new format with simple episode names  
                    for ep_num, (service, video_id) in vidmoly_links.items():
                        episode_name = self._generate_episode_name(int(ep_num), complete_url)
                        all_links[ep_num] = (service, video_id, episode_name)
            
            # Report what we found
            if all_links:
                max_ep = max([int(k) for k in all_links.keys()])
                service_type = list(all_links.values())[0][0] if all_links else "unknown"
                self.debug_print(f"Found {len(all_links)} episodes (1-{max_ep}) using {service_type}")
            else:
                self.debug_print("No episodes found in any format")
            
            return all_links
        except requests.RequestException as e:
            print(f"Error fetching episodes: {e}")
            return {}

    def get_video_url(self, video_data):
        try:
            # Handle both old format (type, id) and new format (type, id, name)
            if len(video_data) == 3:
                video_type, video_id, episode_name = video_data
                print(f"{B}üé¨ Fetching: {M}{episode_name}{X} ({video_type}:{video_id})")
            else:
                video_type, video_id = video_data
                print(f"{B}üé¨ Fetching video: {M}{video_type}:{video_id}{X}")
            
            if video_type == 'sibnet':
                return self._get_sibnet_url(video_id)
            elif video_type == 'vidmoly':
                return self._get_vidmoly_url(video_id)
            else:
                print(f"Unsupported video type: {video_type}")
                return None
                
        except Exception as e:
            print(f"Error getting video URL: {e}")
            return None
    
    def _get_sibnet_url(self, video_id):
        try:
            url = f"https://video.sibnet.ru/shell.php"
            response = self.session.get(url, params={"videoid": video_id})
            response.raise_for_status()
            html_content = response.text
            print(f"{Y}üîç Analyzing Sibnet content...{X}")
            match = re.search(r'player\.src\(\[\{src: "/v/([^/]+)/', html_content)
            if match:
                video_hash = match.group(1)
                url_sibnet = f"https://video.sibnet.ru/v/{video_hash}/{video_id}.mp4"
                print(f"{G}‚úÖ Sibnet URL found{X}")
                headers_sibnet = {
                    **HEADERS_BASE,
                    "range": "bytes=0-",
                    "accept-encoding": "identity",
                    "referer": "https://video.sibnet.ru/",
                }
                response_sibnet = self.session.get(url_sibnet, headers=headers_sibnet, allow_redirects=False)
                if response_sibnet.status_code == 302:
                    return response_sibnet.headers['Location']
                else:
                    print(f"Unexpected Sibnet status code: {response_sibnet.status_code}")
            else:
                print("Sibnet pattern not found in HTML")
            return None
        except requests.RequestException as e:
            print(f"Error getting Sibnet URL: {e}")
            return None
    
    def _get_vidmoly_url(self, video_id):
        """
        Extract direct HLS URL from Vidmoly embed page manually
        """
        vidmoly_domains = ['vidmoly.net', 'vidmoly.to']
        
        for domain in vidmoly_domains:
            try:
                embed_url = f"https://{domain}/embed-{video_id}.html"
                print(f"{Y}üîç Extracting HLS URL from {domain}...{X}")
                
                # Get the embed page with proper headers
                headers = {
                    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:134.0) Gecko/20100101 Firefox/134.0',
                    'Referer': f'https://{domain}/'
                }
                response = self._cached_request('get', embed_url, headers=headers)
                html_content = response.text
                
                # Look for the sources array with HLS URLs
                # Pattern matches: sources: [{file:"https://box-...master.m3u8"}]
                hls_patterns = [
                    r'sources:\s*\[\s*\{\s*file:\s*["\']([^"\']+\.m3u8[^"\']*)["\']',
                    r'file:\s*["\']([^"\']+\.m3u8[^"\']*)["\']',
                    r'"file"\s*:\s*"([^"]+\.m3u8[^"]*)"',
                    r'src:\s*["\']([^"\']+\.m3u8[^"\']*)["\']'
                ]
                
                for pattern in hls_patterns:
                    match = re.search(pattern, html_content, re.IGNORECASE | re.DOTALL)
                    if match:
                        video_url = match.group(1)
                        # Clean up the URL
                        if video_url.startswith('//'):
                            video_url = 'https:' + video_url
                        elif not video_url.startswith('http'):
                            video_url = f"https://{video_url.lstrip('/')}"
                        
                        print(f"{G}‚úÖ Found HLS stream URL{X}")
                        return video_url
                
                # If no HLS found, return embed URL as fallback
                print(f"{Y}‚ö† No HLS found, returning embed URL{X}")
                return embed_url
                
            except Exception as e:
                self.debug_print(f"Error with {domain}: {e}")
                continue
        
        # Final fallback
        fallback_url = f"https://vidmoly.net/embed-{video_id}.html"
        print(f"{Y}üîç Using Vidmoly fallback...{X}")
        return fallback_url

    def get_catalogue(self, query="", vf=False): 
        try:
            url = "https://anime-sama.fr/catalogue/"
            headers = {
                **HEADERS_BASE,  # Use base headers and extend
                "host": "anime-sama.fr",
                "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
                "referer": "https://anime-sama.fr/catalogue/",
                "accept-language": "fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7"
            }
            querystring = {"search": query}
            if vf:
                querystring["langue[]"] = "VF"
            
            self.debug_print(f"GET request to: {url}")
            self.debug_print(f"Querystring: {querystring}")
            
            response = self._cached_request('get', url, headers=headers, params=querystring)
            
            self.debug_print(f"Status code: {response.status_code}")
            
            soup = BeautifulSoup(response.text, 'html.parser')
            animes = []
            urls = []
            
            for card in soup.find_all('a', href=True):
                titre = None
                titre_tag = card.find('h1', class_='text-white font-bold uppercase text-md line-clamp-2')
                if titre_tag:
                    titre = titre_tag.text.strip()
                
                if titre and 'catalogue' in card['href']:
                    animes.append(titre)
                    urls.append(card['href'])
            
            if vf:
                urls = [link.replace("vostfr", "vf") for link in urls]
            
            self.debug_print(f"Found titles: {len(animes)}")
            self.debug_print(f"Titles: {animes}")
            
            return animes, urls
        except requests.RequestException as e:
            print(f"Error fetching catalogue: {e}")
            self.debug_print(f"Full exception: {str(e)}")
            return [], []

def show_available_animes():
    """Show animes that work without VPN (Sibnet-based)"""
    sibnet_animes = [
        "south park", "one piece", "dragon ball", "attack on titan",
        "demon slayer", "jujutsu kaisen", "my hero academia", "bleach",
        "fairy tail", "hunter x hunter", "fullmetal alchemist", "death note"
    ]
    
    print(f"\n{CYAN}{BOLD}üöÄ ANIMES AVAILABLE WITHOUT VPN:{RESET}")
    print(f"{GREEN}These animes use Sibnet and should work directly:{RESET}\n")
    
    downloader = AnimeDownloader(debug=False)
    available_count = 0
    
    for anime in sibnet_animes:
        print(f"{BLUE}Checking {anime.title()}...{RESET}", end=" ")
        animes, urls = downloader.get_catalogue(anime, vf=False)
        
        if animes and urls:
            # Quick check if it uses Sibnet
            try:
                anime_url = urls[0]
                response = requests.get(anime_url, headers=HEADERS_BASE, timeout=5)
                seasons = get_seasons(response.text)
                
                if seasons:
                    season_url = anime_url.rstrip('/') + '/' + seasons[0]['url'].lstrip('/')
                    filever = get_episode_list(season_url)
                    
                    if filever:
                        episodes = downloader.get_anime_episode(season_url, filever)
                        if episodes:
                            first_episode = list(episodes.values())[0]
                            service_type, _ = first_episode
                            
                            if service_type == 'sibnet':
                                print(f"{GREEN}‚úÖ Available ({animes[0]}){RESET}")
                                available_count += 1
                            else:
                                print(f"{YELLOW}‚ö† Uses Vidmoly{RESET}")
                        else:
                            print(f"{RED}‚úó No episodes{RESET}")
                    else:
                        print(f"{RED}‚úó No episode list{RESET}")
                else:
                    print(f"{RED}‚úó No seasons{RESET}")
            except:
                print(f"{RED}‚úó Error{RESET}")
        else:
            print(f"{RED}‚úó Not found{RESET}")
    
    print(f"\n{CYAN}üìä SUMMARY:{RESET}")
    print(f"  {GREEN}‚úì {available_count} animes available without VPN{RESET}")
    print(f"  {YELLOW}‚ö† Vidmoly animes require VPN (Naruto, Sasuke, Boruto...){RESET}")
    print(f"  {BLUE}üí° Use these animes for guaranteed playback{RESET}")

def check_anime_services():
    """Check which streaming service popular animes use"""
    popular_animes = [
        ("naruto", "Naruto"),
        ("one piece", "One Piece"), 
        ("south park", "South Park"),
        ("dragon ball", "Dragon Ball"),
        ("attack on titan", "Attack on Titan")
    ]
    
    print(f"\n{CYAN}{BOLD}üîç CHECKING STREAMING SERVICES:{RESET}")
    downloader = AnimeDownloader(debug=False)
    
    for query, display_name in popular_animes:
        print(f"\n{YELLOW}Checking {display_name}...{RESET}")
        animes, urls = downloader.get_catalogue(query, vf=False)
        
        if animes and urls:
            # Check first result
            anime_url = urls[0]
            try:
                response = requests.get(anime_url, headers=HEADERS_BASE, timeout=5)
                seasons = get_seasons(response.text)
                
                if seasons:
                    season_url = anime_url.rstrip('/') + '/' + seasons[0]['url'].lstrip('/')
                    filever = get_episode_list(season_url)
                    
                    if filever:
                        episodes = downloader.get_anime_episode(season_url, filever)
                        if episodes:
                            # Check what type of episodes we got
                            first_episode = list(episodes.values())[0]
                            service_type, _ = first_episode
                            
                            if service_type == 'sibnet':
                                print(f"  {GREEN}‚úì {display_name}: Uses Sibnet (should work){RESET}")
                            elif service_type == 'vidmoly':
                                print(f"  {YELLOW}‚ö† {display_name}: Uses Vidmoly (may need VPN){RESET}")
                            else:
                                print(f"  {BLUE}? {display_name}: Unknown service type{RESET}")
                        else:
                            print(f"  {RED}‚úó {display_name}: No episodes found{RESET}")
                    else:
                        print(f"  {RED}‚úó {display_name}: Cannot get episode list{RESET}")
                else:
                    print(f"  {RED}‚úó {display_name}: No seasons found{RESET}")
            except Exception as e:
                print(f"  {RED}‚úó {display_name}: Error - {e}{RESET}")
        else:
            print(f"  {RED}‚úó {display_name}: Not found in catalogue{RESET}")
    
    print(f"\n{CYAN}üìù SUMMARY:{RESET}")
    print(f"  {GREEN}‚úì Sibnet animes should work normally{RESET}")
    print(f"  {YELLOW}‚ö† Vidmoly animes may require VPN to access{RESET}")
    print(f"  {BLUE}üí° Use --vf flag for French dub versions{RESET}")

def display_history():
    """Display history with ani-cli style interface"""
    init_db()
    entries = get_history_entries()
    
    if not entries:
        die("No history found!")
    
    # Format entries for fzf display
    display_items = []
    for i, entry in enumerate(entries):
        entry_id, anime_name, episode, saison, url = entry
        display_items.append(f"{i+1}. {anime_name} - {episode} - {saison}")
    
    print(f"\n{MAGENTA}{BOLD}üìö HISTORY:{RESET}")
    selected = fzf_select(display_items, "Select from history: ")
    
    if not selected:
        return
    
    # Parse selection
    try:
        index = int(selected.split('.')[0]) - 1
        if index < 0 or index >= len(entries):
            die("Invalid selection")
        
        entry = entries[index]
        anime_name, episode, saison, url = entry[1:5]
        
        print(f"Playing {anime_name} - {episode} - {saison}")
        
        # Get current episode number
        match = re.search(r'(\d+)$', episode)
        if not match:
            die("Cannot determine current episode")
        
        current_ep = int(match.group(1))
        
        filever = get_episode_list(url)
        if not filever:
            die("Cannot fetch episode list")
        
        downloader = AnimeDownloader()
        episodes = downloader.get_anime_episode(url, filever)
        if not episodes:
            die("No episodes found")
        
        # Find next episode
        ep_keys_int = [int(e) for e in episodes.keys() if e.isdigit()]
        ep_keys_int.sort()
        
        next_ep = None
        for ep in ep_keys_int:
            if ep > current_ep:
                next_ep = ep
                break
        
        if next_ep is None:
            print(f"Already at the last episode: {anime_name} - Episode {current_ep} - {saison}")
            return
        
        video_data = episodes[str(next_ep)]
        print(f"Fetching episode {next_ep}...")
        
        video_url = downloader.get_video_url(video_data)
        if not video_url:
            die("Cannot get video URL")
        
        if video_url.startswith('//'):
            video_url = 'https:' + video_url
        
        print(f"Playing with mpv...")
        try:
            # Add specific options for different video types
            mpv_args = ['mpv', video_url, '--fullscreen']
            if 'vidmoly.net' in video_url:
                # Simple mpv call for Vidmoly URLs  
                mpv_args = ['mpv', video_url, '--fullscreen']
            
            subprocess.run(mpv_args, check=True)
            add_to_history(
                anime_name=anime_name,
                episode=f"Episode {next_ep}",
                saison=saison,
                url=url
            )
        except FileNotFoundError:
            die("mpv is not installed")
        except subprocess.CalledProcessError as e:
            if 'vidmoly.to' in video_url:
                print(RED + "‚úó Vidmoly playback failed" + RESET)
                print(YELLOW + " Try using a VPN or select animes that use Sibnet" + RESET)
                die("Vidmoly not accessible")
            else:
                die(f"Playback error: {e}")
        except Exception as e:
            die(f"Playback error: {e}")
        
    except (ValueError, IndexError):
        die("Invalid selection format")

def main():
    show_banner()
    check_deps()
    
    parser = argparse.ArgumentParser(
        description="anime-sama CLI with ani-cli style interface",
        add_help=False
    )
    parser.add_argument("query", nargs="*", help="Search query")
    parser.add_argument("-c", "--continue", action="store_true", 
                       dest="continuer", help="Continue from history")
    parser.add_argument("--vf", action="store_true", 
                       help="Search for VF only")
    parser.add_argument("--debug", action="store_true", 
                       help="Debug mode")
    parser.add_argument("--check-services", action="store_true",
                       help="Show which streaming service each anime uses")
    parser.add_argument("--available-only", action="store_true",
                       help="Show only animes that work without VPN (Sibnet-based)")
    parser.add_argument("--suggest-working", action="store_true",
                       help="Suggest working alternatives if the requested anime uses Vidmoly")
    parser.add_argument("-h", "--help", action="store_true", 
                       help="Show help")
    
    args = parser.parse_args()
    
    if args.help:
        print("""
Usage: anime-sama-cli [OPTIONS] [SEARCH_TERM]

Options:
    -c, --continue       Continue watching from history
    --vf                Search for VF (French dub) only
    --debug             Enable debug mode
    --check-services    Show which streaming service each anime uses
    --available-only    Show only animes that work without VPN (Sibnet)
    -h, --help          Show this help

Examples:
    anime-sama-cli                    # Interactive search
    anime-sama-cli naruto             # Search for "naruto"
    anime-sama-cli -c                 # Show history
    anime-sama-cli --vf one piece     # Search "one piece" in VF
    anime-sama-cli --check-services   # Check service compatibility
    anime-sama-cli --available-only   # Show only VPN-free animes
        """)
        return
    
    if args.continuer:
        display_history()
        return
    
    if args.check_services:
        check_anime_services()
        return
    
    if args.available_only:
        show_available_animes()
        return
    
    # Remove the problematic suggest_working option for now
    
    # Main search logic - ani-cli style
    query = " ".join(args.query) if args.query else ""
    
    if not query:
        query = search_prompt()
    
    print(f"üîç Searching for: {query}")
    
    # Warn about Vidmoly issues and suggest VF versions
    if any(anime in query.lower() for anime in ['naruto', 'sasuke', 'boruto']):
        if not args.vf:
            print(f"{YELLOW}‚ö† Note: Naruto VOSTFR uses Vidmoly (may be blocked){RESET}")
            print(f"{GREEN}üí° Try: --vf flag for French version (uses Sibnet - works better){RESET}")
            print(f"{BLUE}   Example: ./anisama-cli --vf naruto{RESET}")
        else:
            print(f"{GREEN}‚úÖ Using Naruto VF (French) - should work well (Sibnet){RESET}")
    
    try:
        downloader = AnimeDownloader(debug=args.debug)
        animes, urls = downloader.get_catalogue(query, vf=args.vf)
    except requests.exceptions.ConnectionError:
        show_error_with_solutions('network', 'Cannot connect to anime-sama.fr')
        die("Network connection failed")
    except requests.exceptions.Timeout:
        show_error_with_solutions('network', 'Request timeout')
        die("Connection timeout")
    except Exception as e:
        if args.debug:
            print(f"{RED}Debug: {str(e)}{RESET}")
        show_error_with_solutions('network')
        die("Failed to fetch anime catalogue")
    
    if not animes:
        show_error_with_solutions('no_results', f'Query: "{query}"')
        die("No results found")
    
    print(f"\n{CYAN}{BOLD}üìã SEARCH RESULTS:{RESET}")
    
    # Format results for fzf
    display_items = []
    for i, anime in enumerate(animes):
        display_items.append(f"{i+1}. {anime}")
    
    selected_anime_str = fzf_select(display_items, "Select anime: ")
    if not selected_anime_str:
        die("No anime selected")
    
    # Parse selection
    try:
        selected_index = int(selected_anime_str.split('.')[0]) - 1
        if selected_index < 0 or selected_index >= len(animes):
            die("Invalid selection")
    except (ValueError, IndexError):
        die("Invalid selection format")
    
    anime_name = animes[selected_index]
    anime_url = urls[selected_index]
    
    print(f"Selected: {anime_name}")
    
    # Get seasons
    response = requests.get(anime_url, headers=HEADERS_BASE)
    seasons = get_seasons(response.text)
    
    if not seasons:
        die("No seasons found")
    
    print(f"\n{YELLOW}{BOLD}üé≠ SEASONS:{RESET}")
    
    # Format seasons for fzf
    season_items = []
    for i, season in enumerate(seasons):
        season_items.append(f"{i+1}. {season['name']}")
    
    selected_season_str = fzf_select(season_items, "Select season: ")
    if not selected_season_str:
        die("No season selected")
    
    # Parse season selection
    try:
        season_index = int(selected_season_str.split('.')[0]) - 1
        if season_index < 0 or season_index >= len(seasons):
            die("Invalid season selection")
    except (ValueError, IndexError):
        die("Invalid season selection format")
    
    selected_season = seasons[season_index]
    season_url = anime_url.rstrip('/') + '/' + selected_season['url'].lstrip('/')
    
    if args.vf:
        season_url = season_url.replace("vostfr", "vf")
    
    print(f"Season URL: {season_url}")
    
    # Get episodes
    filever = get_episode_list(season_url)
    if not filever:
        die("Cannot fetch episode list")
    
    episodes = downloader.get_anime_episode(season_url, filever)
    if not episodes:
        die("No episodes found")
    
    print(f"\n{BLUE}{BOLD}üé¨ EPISODES:{RESET}")
    
    # Format episodes for fzf with real names
    ep_items = []
    ep_keys = list(episodes.keys())
    for i, ep_key in enumerate(ep_keys):
        episode_data = episodes[ep_key]
        # Extract episode name if available
        if len(episode_data) == 3:
            _, _, episode_name = episode_data
            ep_items.append(f"{i+1}. {episode_name}")
        else:
            ep_items.append(f"{i+1}. Episode {ep_key}")
    
    selected_episode_str = fzf_select(ep_items, "Select episode: ")
    if not selected_episode_str:
        die("No episode selected")
    
    # Parse episode selection
    try:
        ep_index = int(selected_episode_str.split('.')[0]) - 1
        if ep_index < 0 or ep_index >= len(ep_keys):
            die("Invalid episode selection")
    except (ValueError, IndexError):
        die("Invalid episode selection format")
    
    selected_ep = ep_keys[ep_index]
    video_data = episodes[selected_ep]
    
    print(f"Fetching episode {selected_ep}...")
    
    video_url = downloader.get_video_url(video_data)
    if not video_url:
        die("Cannot get video URL")
    
    if video_url.startswith('//'):
        video_url = 'https:' + video_url
    
    print(f"Playing with mpv...")
    try:
        # Configure mpv arguments based on video source
        if 'vidmoly' in video_url.lower():
            print(f"{YELLOW}üéØ Attempting Vidmoly playback...{RESET}")
            # Use special headers for Vidmoly URLs
            mpv_args = [
                'mpv', video_url, '--fullscreen',
                '--user-agent=Mozilla/5.0 (X11; Linux x86_64; rv:134.0) Gecko/20100101 Firefox/134.0',
                '--referrer=https://vidmoly.net/'
            ]
        elif '.m3u8' in video_url or 'vmwesa.online' in video_url:
            print(f"{YELLOW}üéØ Playing HLS stream...{RESET}")
            # Direct HLS stream from yt-dlp extraction
            mpv_args = [
                'mpv', video_url, '--fullscreen',
                '--user-agent=Mozilla/5.0 (X11; Linux x86_64; rv:134.0) Gecko/20100101 Firefox/134.0',
                '--referrer=https://vidmoly.net/'
            ]
        else:
            # For other sources (Sibnet, etc.)
            mpv_args = ['mpv', video_url, '--fullscreen']
        
        print(f"{BLUE}Starting playback...{RESET}")
        subprocess.run(mpv_args, check=True)
        
        # Determine season info for history
        saison = selected_season['name']
        if "saison" not in saison.lower():
            match = re.search(r'/saison(\d+)', season_url, re.IGNORECASE)
            if match:
                saison = f"Saison {match.group(1)}"
            else:
                saison = selected_season['name']
        
        # Add version info
        if "vostfr" in season_url.lower():
            version_str = "VOSTFR"
        elif re.search(r'/vf/?', season_url.lower()):
            version_str = "VF"
        else:
            version_str = ""
        
        if version_str and version_str.lower() not in saison.lower():
            saison = f"{saison} - {version_str}"
        
        add_to_history(
            anime_name=anime_name,
            episode=f"Episode {selected_ep}",
            saison=saison,
            url=season_url
        )
        
    except FileNotFoundError:
        show_error_with_solutions('deps', 'mpv not found')
        die("mpv is not installed")
    except subprocess.CalledProcessError as e:
        if 'vidmoly' in video_url.lower():
            print(RED + "‚úó Vidmoly playback failed" + RESET)
            print(YELLOW + "  This anime uses Vidmoly service which may be blocked" + RESET)
            show_error_with_solutions('playback', 'Vidmoly access issue')
            die("Vidmoly streaming failed")
        else:
            show_error_with_solutions('playback', f'Exit code: {e.returncode}')
            die(f"Media player error: {e}")
    except Exception as e:
        show_error_with_solutions('playback')
        die(f"Unexpected playback error: {e}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print(f"\n{YELLOW}Interrupted by user{RESET}")
        sys.exit(0)
    except Exception as e:
        die(f"Unexpected error: {e}")